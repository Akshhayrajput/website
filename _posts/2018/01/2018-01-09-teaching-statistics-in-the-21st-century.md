---
layout: post
authors: ["Greg Wilson"]
title: "Teaching Statistics in the 21st Century"
date: 2018-01-09
time: "02:00:00"
category: ["Teaching", "Statistics"]
---

The late 1980s saw a wave of new undergraduate programs launched in computational physics,
as the advent of affordable workstations and PCs made the power to compute and simulate more accessible.
A decade later,
though,
many of those programs had drastically scaled back their ambitions or quietly wound down.
The problem wasn't the programming:
the problem was that whenever a curriculum is designed as "X plus some Y",
it's the Y that gets cut when time runs short,
budgets are squeezed,
or tough hiring decisions need to be made.
"Computational physics" became
"the physics we've always taught, but with assignments on computers"
and then just "the physics we've always taught".

That experience is part of why I'm so excited by things like Daniel Kaplan's 2017 paper
"[Teaching stats for data science](https://peerj.com/preprints/3205/)",
which is a great example of how some faculty are re-thinking pedagogical approaches from the ground up.
Kaplan argues that much of what we currently teach in introductory stats courses
is left over from a time when data was scarce and calculation was hard.
In its place,
he advocates a ten-step calculation-first approach:

1.  Data tables
2.  Data graphics
3.  Model functions
4.  Model training
5.  Effect size and covariates
6.  Displays of distributions
7.  Bootstrap replication
8.  Prediction error
9.  Comparing models
10. Generalization and causality

UBC's [Stat 545](http://stat545.com/) course is another great example
of how people are not just putting old wine in new bottles,
but approaching their subject from an entirely new angles.
If you have any favorite examples,
please add them to the comments–I'm sure our community would enjoy hearing about them.

> **Abstract**
>
> The familiar mathematical topics of introductory statistics–means,
> proportions, t-tests, normal and t distributions, chi-squared,
> etc.–are a product of the first half of the 20th century. Naturally,
> they reflect the statistical conditions of that era: scarce,
> e.g. n<10, data originating in benchtop or agricultural experiments;
> algorithms communicated via algebraic formulas. Today, applied
> statistics relates to a different environment: software is the means
> of algorithmic communication, observational and "unplanned" data are
> interpreted for causal relationships, and data are large both in n
> and the number of variables. This change in situation calls for a
> thorough rethinking of the topics in and approach to statistics
> education. This paper presents a set of ten organizing blocks for
> intro stats that are better suited to today's environment.
